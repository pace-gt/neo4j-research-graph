\doxysection{Slurm\+Job.\+Slurm\+Job Class Reference}
\hypertarget{class_slurm_job_1_1_slurm_job}{}\label{class_slurm_job_1_1_slurm_job}\index{SlurmJob.SlurmJob@{SlurmJob.SlurmJob}}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_slurm_job_1_1_slurm_job_a8ef5c40a61a26d191645b7cff05b85a8}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, account, python\+\_\+env\+\_\+location, num\+\_\+nodes=1, cores\+\_\+per\+\_\+node=4, mem\+\_\+per\+\_\+core=\textquotesingle{}7G\textquotesingle{}, job\+\_\+duration=\textquotesingle{}3\+:00\+:00\textquotesingle{})
\item 
\mbox{\hyperlink{class_slurm_job_1_1_slurm_job_a72c79e9e1d0012673919404156da4aae}{remove\+\_\+duplicates}} (self)
\item 
\mbox{\hyperlink{class_slurm_job_1_1_slurm_job_a71b9493100437f493880cc1bcb58ef21}{download\+\_\+files}} (self)
\item 
\mbox{\hyperlink{class_slurm_job_1_1_slurm_job_a5890dae9e209eb8029e089c16a171ab8}{upload\+\_\+to\+\_\+neo4j}} (self, url, username, password, database)
\item 
\mbox{\hyperlink{class_slurm_job_1_1_slurm_job_a666c12fe8852581bd591c04338e585cb}{run\+\_\+tests\+\_\+on\+\_\+cleaning}} (self)
\item 
\mbox{\hyperlink{class_slurm_job_1_1_slurm_job_aa524009a04b18abab5a08ec31cfea1c2}{print\+\_\+nums\+\_\+in\+\_\+file}} (self)
\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{class_slurm_job_1_1_slurm_job_af4452f14eb240ed4eefe709697810c8c}\label{class_slurm_job_1_1_slurm_job_af4452f14eb240ed4eefe709697810c8c} 
{\bfseries account}
\item 
\Hypertarget{class_slurm_job_1_1_slurm_job_a5851903262284e29b0512ddc13d7b991}\label{class_slurm_job_1_1_slurm_job_a5851903262284e29b0512ddc13d7b991} 
{\bfseries num\+\_\+nodes}
\item 
\Hypertarget{class_slurm_job_1_1_slurm_job_a000368e76f9d36c9f3bb3fabdeae335b}\label{class_slurm_job_1_1_slurm_job_a000368e76f9d36c9f3bb3fabdeae335b} 
{\bfseries cores\+\_\+per\+\_\+node}
\item 
\Hypertarget{class_slurm_job_1_1_slurm_job_a0e65aa3f793d0ad984bb34106feac813}\label{class_slurm_job_1_1_slurm_job_a0e65aa3f793d0ad984bb34106feac813} 
{\bfseries mem\+\_\+per\+\_\+core}
\item 
\Hypertarget{class_slurm_job_1_1_slurm_job_a7ef20e23cb56796b7c966f4353400668}\label{class_slurm_job_1_1_slurm_job_a7ef20e23cb56796b7c966f4353400668} 
{\bfseries job\+\_\+duration}
\item 
\Hypertarget{class_slurm_job_1_1_slurm_job_a2687f790912f3e3c1cee3abb363a03b9}\label{class_slurm_job_1_1_slurm_job_a2687f790912f3e3c1cee3abb363a03b9} 
{\bfseries python\+\_\+env\+\_\+location}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}A class representing a slurm job

Imports
-------
Uses the File class from this project
os
Popen, PIPE from subprocess

Methods
-------
remove_duplicates():
    Create and submit a job to remove all duplicates from the downloaded files
download_files():
    Create and submit a job to download all files
upload_to_neo4j():
    Create and submit a job to upload all nodes to Neo4j
run_tests_on_cleaning():
    Create and submit a job to run multiple tests on the cleaning portion
print_nums_in_files()
    Create and submit a job to print the number of nodes in each file
__create_slurm_job(file_name, job_name="neo4j"):
    Creates a job with the given characteristics
__create_parallel_slurm_job(file_name, job_name="neo4j, array_size=1):
    Creates a parallel job with the given characteristics
__execute_slurm_job(self, file_name, dependency=None):
    Submits a given job to the cluster
\end{DoxyVerb}
 

\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{class_slurm_job_1_1_slurm_job_a8ef5c40a61a26d191645b7cff05b85a8}\label{class_slurm_job_1_1_slurm_job_a8ef5c40a61a26d191645b7cff05b85a8} 
\index{SlurmJob.SlurmJob@{SlurmJob.SlurmJob}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!SlurmJob.SlurmJob@{SlurmJob.SlurmJob}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily Slurm\+Job.\+Slurm\+Job.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{account,  }\item[{}]{python\+\_\+env\+\_\+location,  }\item[{}]{num\+\_\+nodes = {\ttfamily 1},  }\item[{}]{cores\+\_\+per\+\_\+node = {\ttfamily 4},  }\item[{}]{mem\+\_\+per\+\_\+core = {\ttfamily \textquotesingle{}7G\textquotesingle{}},  }\item[{}]{job\+\_\+duration = {\ttfamily \textquotesingle{}3\+:00\+:00\textquotesingle{}} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Constructs attributes for a SlurmJob object

Parameters
----------
account: str
    Account of the pace user
python_env_location: str
    Location of python virtual environment
    If following the docs on submitting a pace job, the location will be:
    /storage/coda1/p-pace-user/0/<USERNAME>/test_installs/neo4j_venv/bin/activate
num_nodes: str, optional
    Number of nodes to use for job
    Default value: 1
cores_per_node: str, optional
    Number of cores per node to use for job
    Default value: 4
mem_per_core: str, optional
    Memory to use per core
    Default value: 7G
job_duration: str, optional
    Time allotted for job
    In format HH:MM:SS
    Default value: 3:00:00
\end{DoxyVerb}
 

\doxysubsection{Member Function Documentation}
\Hypertarget{class_slurm_job_1_1_slurm_job_a71b9493100437f493880cc1bcb58ef21}\label{class_slurm_job_1_1_slurm_job_a71b9493100437f493880cc1bcb58ef21} 
\index{SlurmJob.SlurmJob@{SlurmJob.SlurmJob}!download\_files@{download\_files}}
\index{download\_files@{download\_files}!SlurmJob.SlurmJob@{SlurmJob.SlurmJob}}
\doxysubsubsection{\texorpdfstring{download\_files()}{download\_files()}}
{\footnotesize\ttfamily Slurm\+Job.\+Slurm\+Job.\+download\+\_\+files (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create and submit a job to download all files
Creates an sbatch file to submit: download_files.sbatch
Uses Download.py

Requirements
------------
None

Parameters
----------
None

Returns
-------
None
\end{DoxyVerb}
 \Hypertarget{class_slurm_job_1_1_slurm_job_aa524009a04b18abab5a08ec31cfea1c2}\label{class_slurm_job_1_1_slurm_job_aa524009a04b18abab5a08ec31cfea1c2} 
\index{SlurmJob.SlurmJob@{SlurmJob.SlurmJob}!print\_nums\_in\_file@{print\_nums\_in\_file}}
\index{print\_nums\_in\_file@{print\_nums\_in\_file}!SlurmJob.SlurmJob@{SlurmJob.SlurmJob}}
\doxysubsubsection{\texorpdfstring{print\_nums\_in\_file()}{print\_nums\_in\_file()}}
{\footnotesize\ttfamily Slurm\+Job.\+Slurm\+Job.\+print\+\_\+nums\+\_\+in\+\_\+file (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create and submit a job to print the number of nodes in each file
Creates the following sbatch files:
counting.sbatch
Uses the following methods:
File.check_num_in_json()
Check output files for results

Requirements
------------
openalex_author_dump_edit.json
openalex_work_dump_edit.json
openalex_collab_dump_edit.json
openalex_institution_dump_edit.json

Parameters
----------
None

Returns
-------
None
\end{DoxyVerb}
 \Hypertarget{class_slurm_job_1_1_slurm_job_a72c79e9e1d0012673919404156da4aae}\label{class_slurm_job_1_1_slurm_job_a72c79e9e1d0012673919404156da4aae} 
\index{SlurmJob.SlurmJob@{SlurmJob.SlurmJob}!remove\_duplicates@{remove\_duplicates}}
\index{remove\_duplicates@{remove\_duplicates}!SlurmJob.SlurmJob@{SlurmJob.SlurmJob}}
\doxysubsubsection{\texorpdfstring{remove\_duplicates()}{remove\_duplicates()}}
{\footnotesize\ttfamily Slurm\+Job.\+Slurm\+Job.\+remove\+\_\+duplicates (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create and submit a job to remove all duplicates from the downloaded files
Creates an sbatch file to submit: clean_data.sbatch
Uses the following methods:
Author.remove_duplicate_authors_and_collabs()
Institution.remove_duplicate_institutions()
Work.remove_duplicate_works()

Requirements
------------
openalex_author_dump.json
openalex_work_dump.json
openalex_collab_dump.json
openalex_institution_dump.json

Parameters
----------
None

Returns
-------
None
\end{DoxyVerb}
 \Hypertarget{class_slurm_job_1_1_slurm_job_a666c12fe8852581bd591c04338e585cb}\label{class_slurm_job_1_1_slurm_job_a666c12fe8852581bd591c04338e585cb} 
\index{SlurmJob.SlurmJob@{SlurmJob.SlurmJob}!run\_tests\_on\_cleaning@{run\_tests\_on\_cleaning}}
\index{run\_tests\_on\_cleaning@{run\_tests\_on\_cleaning}!SlurmJob.SlurmJob@{SlurmJob.SlurmJob}}
\doxysubsubsection{\texorpdfstring{run\_tests\_on\_cleaning()}{run\_tests\_on\_cleaning()}}
{\footnotesize\ttfamily Slurm\+Job.\+Slurm\+Job.\+run\+\_\+tests\+\_\+on\+\_\+cleaning (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create and submit a job to run multiple tests on the cleaning portion
Creates the following sbatch files:
cleaning_tests.sbatch
Uses the following methods:
File.check_for_duplicates()
File.compare_to_edit
Author.test_no_duplicates_in_author_and_collab
Author.check_no_lost_collabs
Check output files for results

Requirements
------------
openalex_author_dump.json
openalex_work_dump.json
openalex_collab_dump.json
openalex_institution_dump.json
openalex_author_dump_edit.json
openalex_work_dump_edit.json
openalex_collab_dump_edit.json
openalex_institution_dump_edit.json

Parameters
----------
None

Returns
-------
None
\end{DoxyVerb}
 \Hypertarget{class_slurm_job_1_1_slurm_job_a5890dae9e209eb8029e089c16a171ab8}\label{class_slurm_job_1_1_slurm_job_a5890dae9e209eb8029e089c16a171ab8} 
\index{SlurmJob.SlurmJob@{SlurmJob.SlurmJob}!upload\_to\_neo4j@{upload\_to\_neo4j}}
\index{upload\_to\_neo4j@{upload\_to\_neo4j}!SlurmJob.SlurmJob@{SlurmJob.SlurmJob}}
\doxysubsubsection{\texorpdfstring{upload\_to\_neo4j()}{upload\_to\_neo4j()}}
{\footnotesize\ttfamily Slurm\+Job.\+Slurm\+Job.\+upload\+\_\+to\+\_\+neo4j (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{url,  }\item[{}]{username,  }\item[{}]{password,  }\item[{}]{database }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create and submit a job to upload all nodes to Neo4j
Creates the following sbatch files:
upload_inst.sbatch
upload_collabs.sbatch
upload_authors.sbatch
upload_works.sbatch
upload_authored.sbatch
Uses the following methods:
Institution.upload_institutions()
Author.upload_collabs_parallel()
Author.upload_current_gt_authors()
Work.upload_works_parallel()
Work.create_authored_relationship()
Uses job dependencies to ensure the jobs run in that order

Requirements
------------
openalex_author_dump_edit.json
openalex_work_dump_edit.json
openalex_collab_dump_edit.json
openalex_institution_dump_edit.json

Parameters
----------
url: str
    URL of the database to connect and upload the nodes to
username: str
    Username of Neo4j user
password: str
    Password of Neo4j user
database: str
    Specific database to upload to

Returns
-------
None
\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
Slurm\+Job.\+py\end{DoxyCompactItemize}
